{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9438254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 10:42:54,212 3469687410[INFO]: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=256, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (7): Tanh()\n",
      "  (8): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n",
      "2025-08-17 10:42:55,326 3469687410[INFO]: Loading /home/ich/Schreibtisch/Ki/artevis/src/images/mond.jpg\n",
      "2025-08-17 10:42:55,367 3469687410[INFO]: ref_shape=(246, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1173881/3469687410.py:73: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
      "  sub = fig.add_subplot()\n",
      "train:mond:   0%|          | 1/1000000 [00:00<62:51:08,  4.42step/s, best=11746.0166, loss=11746.0166]/tmp/ipykernel_1173881/3469687410.py:111: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
      "  sub = fig.add_subplot(2, 1, 2)\n",
      "/tmp/ipykernel_1173881/3469687410.py:115: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
      "  sub = fig.add_subplot(2, len(weights) + 2, len(weights) + 1)\n",
      "/tmp/ipykernel_1173881/3469687410.py:118: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
      "  sub = fig.add_subplot(2, len(weights) + 2, len(weights) + 2)\n",
      "/tmp/ipykernel_1173881/3469687410.py:137: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
      "  sub = fig.add_subplot(2, len(weights) + 2, i + 1)\n",
      "/tmp/ipykernel_1173881/3469687410.py:90: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
      "  sub = fig.add_subplot()\n",
      "train:mond:   0%|          | 10/1000000 [00:00<18:23:49, 15.10step/s, best=10967.1504, loss=10967.1504]/tmp/ipykernel_1173881/3469687410.py:110: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
      "  fig.clear()\n",
      "train:mond:   4%|▍         | 40865/1000000 [50:40<19:49:24, 13.44step/s, best=86.4161, loss=87.0078, note=early-stop]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 11:33:38,465 3469687410[INFO]: state_dict gespeichert: /home/ich/Schreibtisch/Ki/artevis/src/output/mond/model.pt\n",
      "2025-08-17 11:33:38,570 3469687410[INFO]: Model-JSON geschrieben: /home/ich/Schreibtisch/Ki/artevis/src/webroot/models/mond.json\n",
      "2025-08-17 11:33:38,572 3469687410[INFO]: Manifest aktualisiert: /home/ich/Schreibtisch/Ki/artevis/src/webroot/models/manifest.json (3 Einträge)\n",
      "2025-08-17 11:33:38,575 3469687410[INFO]: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=256, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (7): Tanh()\n",
      "  (8): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n",
      "2025-08-17 11:33:38,576 3469687410[INFO]: Loading /home/ich/Schreibtisch/Ki/artevis/src/images/nebelmeer.jpg\n",
      "2025-08-17 11:33:38,611 3469687410[INFO]: ref_shape=(256, 202, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:nebelmeer:   4%|▎         | 36543/1000000 [39:44<17:27:53, 15.32step/s, best=40.9781, loss=41.2288, note=early-stop]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 12:13:25,875 3469687410[INFO]: state_dict gespeichert: /home/ich/Schreibtisch/Ki/artevis/src/output/nebelmeer/model.pt\n",
      "2025-08-17 12:13:25,987 3469687410[INFO]: Model-JSON geschrieben: /home/ich/Schreibtisch/Ki/artevis/src/webroot/models/nebelmeer.json\n",
      "2025-08-17 12:13:25,988 3469687410[INFO]: Manifest aktualisiert: /home/ich/Schreibtisch/Ki/artevis/src/webroot/models/manifest.json (4 Einträge)\n",
      "2025-08-17 12:13:25,992 3469687410[INFO]: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=256, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (7): Tanh()\n",
      "  (8): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n",
      "2025-08-17 12:13:25,993 3469687410[INFO]: Loading /home/ich/Schreibtisch/Ki/artevis/src/images/schrei.jpg\n",
      "2025-08-17 12:13:26,035 3469687410[INFO]: ref_shape=(256, 205, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:schrei:  28%|██▊       | 283406/1000000 [8:16:18<20:54:54,  9.52step/s, best=125.5102, loss=128.0563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 20:29:44,289 3469687410[INFO]: EXIT -- Abort\n"
     ]
    }
   ],
   "source": [
    "# train_and_export.py  — Checkpoints (10k), Resume, Größen ins Manifest,\n",
    "# OOM-freundliche Hi-Res-Inferenz per Tiling, schlanke Logs/Plots\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import colors\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "\n",
    "# ---- Headless-Backend: kein Tkinter nötig ----\n",
    "matplotlib.use('Agg')\n",
    "plt.rcParams['font.family'] = 'cmr10'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "DPI: int = 100\n",
    "SCALE: float = 2\n",
    "GR = (1 + np.sqrt(5)) / 2 - 1\n",
    "\n",
    "GRAY: plt.Colormap = colors.LinearSegmentedColormap.from_list('gray', plt.get_cmap('gray')(np.linspace(0, 1., 100)))\n",
    "SEISMIC: plt.Colormap = colors.LinearSegmentedColormap.from_list('seismic', plt.get_cmap('seismic')(np.linspace(0, 1., 100)))\n",
    "SEISMIC_NEGATIVE: plt.Colormap = colors.LinearSegmentedColormap.from_list('seismic_neg', plt.get_cmap('seismic')(np.linspace(0., .5, 50)))\n",
    "SEISMIC_POSITIVE: plt.Colormap = colors.LinearSegmentedColormap.from_list('seismic_pos', plt.get_cmap('seismic')(np.linspace(.5, 1., 50)))\n",
    "\n",
    "# ==== AUSGABE-ORTE (Jupyter-/Script-freundlich) ====\n",
    "ROOT: Path = Path.cwd()              # funktioniert auch in Jupyter\n",
    "OUTPUT_DIR: Path = ROOT / 'output'\n",
    "IMAGE_DIR: Path = ROOT / 'images'\n",
    "MODELS_DIR: Path = ROOT / 'webroot' / 'models'\n",
    "\n",
    "# ---- Auto-Discovery: alle Bilder in images/ (ohne Endung) als Projekte ----\n",
    "ALLOWED_EXTS = ['.png', '.jpg', '.jpeg', '.bmp', '.webp']\n",
    "\n",
    "def discover_projects(image_dir: Path) -> List[str]:\n",
    "    if not image_dir.exists():\n",
    "        image_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return []\n",
    "    projects = []\n",
    "    for p in image_dir.iterdir():\n",
    "        if p.is_file() and p.suffix.lower() in ALLOWED_EXTS:\n",
    "            projects.append(p.stem)\n",
    "    projects.sort()\n",
    "    return projects\n",
    "\n",
    "AUTO_DISCOVER_PROJECTS = True\n",
    "PROJECTS: List[str] = discover_projects(IMAGE_DIR) if AUTO_DISCOVER_PROJECTS else [\n",
    "    'mona-lisa_1080', 'girl_1080', 'nebelmeer_1080', 'schrei_1080', 'sterne_1080'\n",
    "]\n",
    "\n",
    "SIZE = 256  # Hidden width und Inputbild-Skalierung\n",
    "CHECKPOINT_EVERY = 10_000\n",
    "\n",
    "def save_fig(fig: plt.Figure, path: Path, dpi: float = DPI) -> None:\n",
    "    if path is not None:\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(path, format=path.suffix[1:], transparent=False, dpi=dpi)\n",
    "\n",
    "def save_image(im: np.ndarray, path: Path) -> None:\n",
    "    im = im.astype(np.int32)\n",
    "    im[im > 255] = 255\n",
    "    im[im < 0] = 0\n",
    "    fig = plt.Figure(figsize=(im.shape[1], im.shape[0]), dpi=1)\n",
    "    sub = fig.add_subplot()\n",
    "    sub.set_axis_off()\n",
    "    sub.imshow(im[:, :, ::-1], interpolation='nearest')\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1)\n",
    "    sub.margins(0, 0)\n",
    "    save_fig(fig, path, 1)\n",
    "\n",
    "def save_art(art: np.ndarray, path: Path) -> None:\n",
    "    w, b = np.nanmin(art), np.nanmax(art)\n",
    "    art = art.copy()\n",
    "    art -= w\n",
    "    if (b - w) != 0:\n",
    "        art *= 255 / (b - w)\n",
    "    im = art.astype(np.int32)\n",
    "    im[im > 255] = 255\n",
    "    im[im < 0] = 0\n",
    "    fig = plt.Figure(figsize=(im.shape[1], im.shape[0]), dpi=1)\n",
    "    sub = fig.add_subplot()\n",
    "    sub.set_axis_off()\n",
    "    sub.imshow(im[:, :, ::-1], interpolation='nearest', zorder=1)\n",
    "    sub.set_xlim(0, im.shape[1])\n",
    "    sub.set_ylim(0, im.shape[0])\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1)\n",
    "    sub.margins(0, 0)\n",
    "    save_fig(fig, path, 1)\n",
    "\n",
    "def save_frame(fig: plt.Figure, n: int, model: torch.nn.Module, im: np.ndarray, art: np.ndarray, losses: List[float]) -> None:\n",
    "    weights = [w.detach().cpu().numpy() for i, w in model.named_parameters() if 'weight' in i][1:-1]\n",
    "    im = im.astype(np.int32)\n",
    "    im[im > 255] = 255\n",
    "    im[im < 0] = 0\n",
    "    art = art.copy()\n",
    "    w, b = np.nanmin(art), np.nanmax(art)\n",
    "    art -= w\n",
    "    if (b - w) != 0:\n",
    "        art *= 255 / (b - w)\n",
    "    art = art.astype(np.int32)\n",
    "    fig.clear()\n",
    "    sub = fig.add_subplot(2, 1, 2)\n",
    "    sub.set_axis_off()\n",
    "    sub.set_yscale('log', base=10)\n",
    "    sub.plot(losses[-5_000:], c='r')\n",
    "    sub = fig.add_subplot(2, len(weights) + 2, len(weights) + 1)\n",
    "    sub.set_axis_off()\n",
    "    sub.imshow(im[:, :, ::-1], interpolation='nearest', zorder=1)\n",
    "    sub = fig.add_subplot(2, len(weights) + 2, len(weights) + 2)\n",
    "    sub.set_axis_off()\n",
    "    sub.imshow(art[:, :, ::-1], interpolation='nearest', zorder=1)\n",
    "    sub.set_xlim(0, art.shape[1])\n",
    "    sub.set_ylim(0, art.shape[0])\n",
    "    vmin, vmax = np.nanmin(weights), np.nanmax(weights)\n",
    "    if vmin < 0 < vmax:\n",
    "        norm = colors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "        cmap = SEISMIC\n",
    "    elif vmax == vmin:\n",
    "        norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "        cmap = SEISMIC\n",
    "    elif vmax < 0:\n",
    "        norm = colors.Normalize(vmin=vmin, vmax=0)\n",
    "        cmap = SEISMIC_NEGATIVE\n",
    "    else:\n",
    "        norm = colors.Normalize(vmin=0, vmax=vmax)\n",
    "        cmap = SEISMIC_POSITIVE\n",
    "    for i, w in enumerate(weights):\n",
    "        sub = fig.add_subplot(2, len(weights) + 2, i + 1)\n",
    "        sub.set_axis_off()\n",
    "        sub.set_frame_on(True)\n",
    "        sub.imshow(w, cmap=cmap, norm=norm, interpolation='nearest', zorder=1)\n",
    "    fig.suptitle(f'{n}\\n({np.min(losses):.3f})', fontsize=14)\n",
    "    fig.subplots_adjust(bottom=.1, top=.9, left=0.02, right=.98, wspace=.05, hspace=.05)\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "def artsy(weights: List[torch.Tensor], biases: List[torch.Tensor]) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "    weights = [weights[0]] + [weights[3].rot90(), weights[2].rot90().rot90(), weights[1].rot90().rot90().rot90()] + [weights[4]]\n",
    "    biases = [biases[0]] + [biases[3], biases[2], biases[1]] + [biases[4]]\n",
    "    return weights, biases\n",
    "\n",
    "def find_image_for_project(project: str, image_dir: Path) -> Path:\n",
    "    candidates = [image_dir / f\"{project}{ext}\" for ext in ALLOWED_EXTS]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    existing = sorted([str(p.name) for p in image_dir.glob('*') if p.is_file()])\n",
    "    raise FileNotFoundError(\n",
    "        f\"Kein Bild für Projekt '{project}' gefunden.\\n\"\n",
    "        f\"Erwartet: {', '.join([project+e for e in ALLOWED_EXTS])} in {image_dir}\\n\"\n",
    "        f\"Aktuell vorhanden ({len(existing)}): {existing}\"\n",
    "    )\n",
    "\n",
    "def read_and_resize_image(project: str, size: int, image_dir: Path) -> np.ndarray:\n",
    "    path = find_image_for_project(project, image_dir)\n",
    "    logging.info(f'Loading {path}')\n",
    "    im = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2 konnte die Datei nicht lesen: {path}\")\n",
    "    if im.shape[0] > im.shape[1]:\n",
    "        im = cv2.resize(im, (round(size / im.shape[0] * im.shape[1]), size))\n",
    "    else:\n",
    "        im = cv2.resize(im, (size, round(size / im.shape[1] * im.shape[0])))\n",
    "    return im\n",
    "\n",
    "# ========= Speicher-schonende Inferenz (gekachelt) =========\n",
    "\n",
    "def render_image_tiled(model: nn.Module, H: int, W: int, device: torch.device, tile: int = 256) -> np.ndarray:\n",
    "    out = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for y0 in range(0, H, tile):\n",
    "            y1 = min(H, y0 + tile)\n",
    "            yy, xx = np.mgrid[y0:y1, 0:W]\n",
    "            x_in = np.stack([\n",
    "                yy.reshape(-1) / max(1, (H - 1)),\n",
    "                xx.reshape(-1) / max(1, (W - 1)),\n",
    "            ], axis=1).astype(np.float32)\n",
    "            x_t = torch.from_numpy(x_in).to(device, non_blocking=True)\n",
    "            pred = model(x_t).detach().cpu().numpy().reshape(y1 - y0, W, 3)\n",
    "            out[y0:y1, :, :] = pred\n",
    "            del x_t, pred, x_in, yy, xx\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    return out\n",
    "\n",
    "def render_art_tiled(model: nn.Module, H: int, W: int, device: torch.device, tile: int = 256) -> np.ndarray:\n",
    "    art = copy.deepcopy(model)\n",
    "    ws, bs = [], []\n",
    "    for name, p in art.named_parameters():\n",
    "        if 'weight' in name: ws.append(p.detach())\n",
    "        elif 'bias' in name: bs.append(p.detach())\n",
    "    ws, bs = artsy(ws, bs)\n",
    "    for name, p in art.named_parameters():\n",
    "        if 'weight' in name: p.data = nn.parameter.Parameter(ws.pop(0))\n",
    "        elif 'bias' in name: p.data = nn.parameter.Parameter(bs.pop(0))\n",
    "    art = art.to(device).eval()\n",
    "\n",
    "    out = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    with torch.inference_mode():\n",
    "        for y0 in range(0, H, tile):\n",
    "            y1 = min(H, y0 + tile)\n",
    "            yy, xx = np.mgrid[y0:y1, 0:W]\n",
    "            x_in = np.stack([\n",
    "                yy.reshape(-1) / max(1, (H - 1)),\n",
    "                xx.reshape(-1) / max(1, (W - 1)),\n",
    "            ], axis=1).astype(np.float32)\n",
    "            x_t = torch.from_numpy(x_in).to(device, non_blocking=True)\n",
    "            pred = art(x_t).detach().cpu().numpy().reshape(y1 - y0, W, 3)\n",
    "            out[y0:y1, :, :] = pred\n",
    "            del x_t, pred, x_in, yy, xx\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    del art, ws, bs\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return out\n",
    "\n",
    "# ========= Checkpointing & Export =========\n",
    "\n",
    "def _tensor_to_list(t: torch.Tensor) -> List[List[float]] | List[float]:\n",
    "    return t.detach().cpu().numpy().tolist()\n",
    "\n",
    "def build_layers_from_state_dict(state: Dict[str, torch.Tensor]) -> List[Dict[str, Any]]:\n",
    "    items = [(int(k.split('.')[0]), k, v) for k, v in state.items() if k.endswith('.weight') or k.endswith('.bias')]\n",
    "    items.sort(key=lambda x: (x[0], 0 if x[1].endswith('.weight') else 1))\n",
    "    pairs: List[tuple[torch.Tensor, torch.Tensor]] = []\n",
    "    i = 0\n",
    "    while i < len(items):\n",
    "        idx, key, val = items[i]\n",
    "        if key.endswith('.weight'):\n",
    "            bkey = f\"{idx}.bias\"\n",
    "            bias = None\n",
    "            for j in range(i + 1, len(items)):\n",
    "                if items[j][1] == bkey:\n",
    "                    bias = items[j][2]\n",
    "                    break\n",
    "            if bias is None:\n",
    "                raise RuntimeError(f\"Bias für {key} nicht gefunden\")\n",
    "            pairs.append((val, bias))\n",
    "        i += 1\n",
    "    layers: List[Dict[str, Any]] = []\n",
    "    for li, (W, b) in enumerate(pairs):\n",
    "        layers.append({\"W\": _tensor_to_list(W), \"b\": _tensor_to_list(b)})\n",
    "        if li < len(pairs) - 1:\n",
    "            layers.append({\"act\": \"tanh\"})\n",
    "    return layers\n",
    "\n",
    "def save_model_json(model: nn.Module, project_name: str, shape: Tuple[int, int, int], models_dir: Path = MODELS_DIR) -> Path:\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "    state = model.state_dict()\n",
    "    payload = {\n",
    "        \"name\": project_name,\n",
    "        \"shape\": {\"height\": int(shape[0]), \"width\": int(shape[1]), \"channels\": int(shape[2])},\n",
    "        \"layers\": build_layers_from_state_dict(state)\n",
    "    }\n",
    "    out_path = models_dir / f\"{project_name}.json\"\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "    logging.info(f\"Model-JSON geschrieben: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "def write_manifest(models_dir: Path = MODELS_DIR) -> Path:\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "    files = sorted([p for p in models_dir.glob(\"*.json\") if p.name != \"manifest.json\"])\n",
    "    manifest = []\n",
    "    for p in files:\n",
    "        try:\n",
    "            with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            shape = data.get(\"shape\", {})\n",
    "            manifest.append({\n",
    "                \"name\": data.get(\"name\", p.stem),\n",
    "                \"url\": f\"./{p.name}\",\n",
    "                \"width\": int(shape.get(\"width\", 256)),\n",
    "                \"height\": int(shape.get(\"height\", 256))\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Manifest: Konnte {p} nicht lesen: {e}\")\n",
    "    out_path = models_dir / \"manifest.json\"\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "    logging.info(f\"Manifest aktualisiert: {out_path} ({len(files)} Einträge)\")\n",
    "    return out_path\n",
    "\n",
    "def build_model(width: int, dtype: torch.dtype) -> nn.Sequential:\n",
    "    m = nn.Sequential(\n",
    "        nn.Linear(2, width, bias=True, dtype=dtype),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(width, width, bias=True, dtype=dtype),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(width, width, bias=True, dtype=dtype),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(width, width, bias=True, dtype=dtype),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(width, 3, bias=True, dtype=dtype),\n",
    "    )\n",
    "    return m\n",
    "\n",
    "def checkpoint_dir_for(project: str) -> Path:\n",
    "    d = OUTPUT_DIR / project / 'checkpoints'\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "def save_checkpoint(project: str, step: int, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "                    losses: List[float], ref_shape: Tuple[int,int,int]) -> Path:\n",
    "    ckpt_dir = checkpoint_dir_for(project)\n",
    "    ckpt_path = ckpt_dir / f'ckpt_step{step:07d}.pt'\n",
    "    torch.save({\n",
    "        \"step\": step,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"losses\": losses[-50_000:],  # nicht unendlich wachsen lassen\n",
    "        \"ref_shape\": tuple(int(x) for x in ref_shape)\n",
    "    }, ckpt_path)\n",
    "    # \"latest\" schreiben\n",
    "    latest_path = ckpt_dir / 'latest.pt'\n",
    "    try:\n",
    "        latest_path.unlink(missing_ok=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    ckpt_path.replace(ckpt_path)  # no-op (placeholder für konsistenz)\n",
    "    torch.save({\n",
    "        \"step\": step,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"losses\": losses[-50_000:],\n",
    "        \"ref_shape\": tuple(int(x) for x in ref_shape)\n",
    "    }, latest_path)\n",
    "    logging.info(f\"Checkpoint gespeichert: {ckpt_path.name}\")\n",
    "    return ckpt_path\n",
    "\n",
    "def load_latest_checkpoint(project: str, model: nn.Module, optimizer: Optional[torch.optim.Optimizer]=None\n",
    "                           ) -> Tuple[int, List[float], Optional[Tuple[int,int,int]]]:\n",
    "    ckpt_dir = checkpoint_dir_for(project)\n",
    "    latest = ckpt_dir / 'latest.pt'\n",
    "    start_step = 0\n",
    "    losses: List[float] = []\n",
    "    ref_shape: Optional[Tuple[int,int,int]] = None\n",
    "    if latest.exists():\n",
    "        blob = torch.load(latest, map_location='cpu')\n",
    "        model.load_state_dict(blob[\"model_state\"])\n",
    "        if optimizer is not None and \"optimizer_state\" in blob:\n",
    "            try:\n",
    "                optimizer.load_state_dict(blob[\"optimizer_state\"])\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Optimizer-State konnte nicht geladen werden (weiter mit frischem Optimizer): {e}\")\n",
    "        start_step = int(blob.get(\"step\", 0))\n",
    "        losses = list(blob.get(\"losses\", []))\n",
    "        rs = blob.get(\"ref_shape\")\n",
    "        if rs is not None:\n",
    "            ref_shape = (int(rs[0]), int(rs[1]), int(rs[2]))\n",
    "        logging.info(f\"Resume von Step {start_step} (Checkpoint gefunden).\")\n",
    "    return start_step, losses, ref_shape\n",
    "\n",
    "# ========= Training =========\n",
    "\n",
    "def train(project: str, n: int, frame: int, threshold: float, model: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer, dtype: torch.dtype, device: torch.device,\n",
    "          start_step: int = 0, resume_losses: Optional[List[float]] = None\n",
    "          ) -> Tuple[int, Tuple[int,int,int], List[float], int]:\n",
    "    \"\"\"\n",
    "    Gibt zurück: (frame, ref_shape, losses, last_step)\n",
    "    \"\"\"\n",
    "    im = read_and_resize_image(project, SIZE, IMAGE_DIR)\n",
    "    save_image(im, OUTPUT_DIR / project / 'input.png')\n",
    "\n",
    "    ref_y = torch.tensor(np.array([i for j in im for i in j]), dtype=dtype, device=device)\n",
    "    ref_shape = (int(im.shape[0]), int(im.shape[1]), 3)\n",
    "    logging.info(f\"ref_shape={ref_shape}\")\n",
    "\n",
    "    ref_grid = np.mgrid[0:ref_shape[0], 0:ref_shape[1]]\n",
    "    ref_x = torch.hstack([\n",
    "        torch.tensor(np.array([[i / (ref_shape[0] - 1)] for i in ref_grid[0].flatten()]), dtype=dtype, device=device),\n",
    "        torch.tensor(np.array([[i / (ref_shape[1] - 1)] for i in ref_grid[1].flatten()]), dtype=dtype, device=device),\n",
    "    ])\n",
    "\n",
    "    fig = plt.figure(figsize=(1920 / DPI, 1080 / DPI), dpi=DPI)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    mse = nn.MSELoss(reduction='mean')\n",
    "    model.train()\n",
    "\n",
    "    # Verlaufswerte (fortsetzen, falls vorhanden)\n",
    "    losses: List[float] = resume_losses[:] if resume_losses else []\n",
    "    best = float(min(losses)) if losses else float('inf')\n",
    "\n",
    "    # Fortschrittsbalken von start_step bis n\n",
    "    with logging_redirect_tqdm(), tqdm(\n",
    "        total=n, initial=start_step,\n",
    "        desc=f\"train:{project}\",\n",
    "        unit=\"step\",\n",
    "        dynamic_ncols=True,\n",
    "        leave=True\n",
    "    ) as pbar:\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            err = mse(model.forward(ref_x), ref_y)\n",
    "            err.backward()\n",
    "            return err\n",
    "\n",
    "        last_saved_at = (start_step // CHECKPOINT_EVERY) * CHECKPOINT_EVERY\n",
    "\n",
    "        for i in range(start_step, n):\n",
    "            loss_tensor: torch.Tensor = optimizer.step(closure)\n",
    "            loss_val = float(loss_tensor.detach().cpu().numpy())\n",
    "            losses.append(loss_val)\n",
    "            if loss_val < best:\n",
    "                best = loss_val\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{loss_val:.4f}\", best=f\"{best:.4f}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Frühstopp prüfen\n",
    "            change = abs(np.min(losses[-2_000:-1_000]) - np.min(losses[-1_000:])) if i > 2_000 else np.inf\n",
    "            if i > 2_000 and np.min(losses) < threshold and change < 1:\n",
    "                pbar.set_postfix(loss=f\"{loss_val:.4f}\", best=f\"{best:.4f}\", note=\"early-stop\")\n",
    "                last_step = i\n",
    "                break\n",
    "\n",
    "            # Sparsame Visualisierung\n",
    "            if i % 10 == 0:\n",
    "                art = copy.deepcopy(model).to(device).eval()\n",
    "                weights, biases = [], []\n",
    "                for name, param in art.named_parameters():\n",
    "                    if 'weight' in name:  weights.append(param.detach())\n",
    "                    if 'bias'   in name:  biases.append(param.detach())\n",
    "                weights, biases = artsy(weights, biases)\n",
    "                for name, param in art.named_parameters():\n",
    "                    if 'weight' in name: param.data = nn.parameter.Parameter(weights.pop(0))\n",
    "                    if 'bias'   in name: param.data = nn.parameter.Parameter(biases.pop(0))\n",
    "                with torch.inference_mode():\n",
    "                    a = art.forward(ref_x).detach().cpu().numpy().reshape(ref_shape)\n",
    "                    base = model.forward(ref_x).detach().cpu().numpy().reshape(ref_shape)\n",
    "                save_frame(fig, i, model, base, a, losses)\n",
    "                save_fig(fig, OUTPUT_DIR / project / 'frames' / f'frame_{frame:06d}.png')\n",
    "                save_art(a, OUTPUT_DIR / project / 'art' / f'frame_{frame:06d}.png')\n",
    "                frame += 1\n",
    "                # Cleanup\n",
    "                del art, weights, biases, a, base\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            # === Checkpoint + JSON + Manifest alle 10k Steps ===\n",
    "            if (i - last_saved_at) >= CHECKPOINT_EVERY or i == n - 1:\n",
    "                save_checkpoint(project, i, model, optimizer, losses, ref_shape)\n",
    "                save_model_json(model, project, ref_shape, MODELS_DIR)\n",
    "                write_manifest(MODELS_DIR)\n",
    "                last_saved_at = i\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        else:\n",
    "            # lief bis zum Ende ohne break\n",
    "            last_step = n - 1\n",
    "\n",
    "    # Low-res Output (Train-Auflösung)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        base = model.forward(ref_x).detach().cpu().numpy().reshape(ref_shape)\n",
    "    save_image(base, OUTPUT_DIR / project / 'output.png')\n",
    "\n",
    "    # Hi-Res Eval (8×) — gekachelt\n",
    "    eval_H, eval_W = 8 * ref_shape[0], 8 * ref_shape[1]\n",
    "    base_hi = render_image_tiled(model, eval_H, eval_W, device, tile=256)\n",
    "    save_image(base_hi, OUTPUT_DIR / project / 'eval.png')\n",
    "    del base_hi\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    art_hi = render_art_tiled(model, eval_H, eval_W, device, tile=256)\n",
    "    save_art(art_hi, OUTPUT_DIR / project / 'art.png')\n",
    "    del art_hi\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Große Tensoren freigeben\n",
    "    del im, ref_x, ref_y, ref_grid, fig, base\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return frame, ref_shape, losses, last_step\n",
    "\n",
    "# ========= Main =========\n",
    "\n",
    "def main() -> None:\n",
    "    if not torch.cuda.is_available():\n",
    "        logging.warning(\"CUDA/HIP nicht verfügbar – wechsle auf CPU.\")\n",
    "        device = torch.device('cpu')\n",
    "    else:\n",
    "        device = torch.device('cuda')  # funktioniert auch mit HIP-Backend\n",
    "\n",
    "    dtype = torch.float32\n",
    "    layer = SIZE\n",
    "\n",
    "    if not PROJECTS:\n",
    "        raise SystemExit(\n",
    "            f\"Keine Projekte gefunden. Lege Bilder in {IMAGE_DIR} ab \"\n",
    "            f\"(erlaubte Endungen: {', '.join(ALLOWED_EXTS)}), oder deaktiviere AUTO_DISCOVER_PROJECTS und setze PROJECTS manuell.\"\n",
    "        )\n",
    "\n",
    "    for project in PROJECTS:\n",
    "        model = build_model(layer, dtype).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        start_step, resume_losses, resume_shape = load_latest_checkpoint(project, model, optimizer)\n",
    "\n",
    "        n = 1_000_000\n",
    "        threshold = 100\n",
    "        frame = 1\n",
    "\n",
    "        # ---- Training (mit Resume) ----\n",
    "        frame, ref_shape, losses, last_step = train(\n",
    "            project, n, frame, threshold, model, optimizer, dtype, device,\n",
    "            start_step=start_step, resume_losses=resume_losses\n",
    "        )\n",
    "\n",
    "        # ---- Final speichern ----\n",
    "        pt_path = OUTPUT_DIR / project / 'model.pt'\n",
    "        pt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), pt_path)\n",
    "        logging.info(f\"state_dict gespeichert: {pt_path}\")\n",
    "\n",
    "        save_model_json(model, project, ref_shape, MODELS_DIR)\n",
    "        write_manifest(MODELS_DIR)\n",
    "\n",
    "        # Cleanup pro Projekt\n",
    "        del model, optimizer, losses\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(module)s[%(levelname)s]: %(message)s',\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "        encoding='utf-8',\n",
    "        level=logging.INFO\n",
    "    )\n",
    "    torch.manual_seed(42)\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    try:\n",
    "        main()\n",
    "        logging.info('EXIT -- Success')\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info('EXIT -- Abort')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
